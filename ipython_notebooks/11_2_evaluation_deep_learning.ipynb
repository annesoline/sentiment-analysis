{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-edf_sentiment_analysis",
      "display_name": "Python (env edf_sentiment_analysis)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "anne-soline.guilbert-ly@dataiku.com"
      },
      "lastModifiedOn": 1743164265805
    },
    "customFields": {},
    "dkuGit": {
      "lastInteraction": 0
    },
    "associatedRecipe": "11_2_evaluation_deep_learning",
    "createdOn": 1743164265805,
    "creator": "anne-soline.guilbert-ly@dataiku.com",
    "tags": [
      "recipe-editor"
    ],
    "modifiedBy": "anne-soline.guilbert-ly@dataiku.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Packages"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n\nimport pandas as pd\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nfrom edf_commons.modelling import preprocess_data_for_dl\n\nimport tempfile\nfrom datetime import datetime\nimport shutil\nimport pickle\nimport os"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global variables"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project \u003d dataiku.Project()\nvariables \u003d project.get_variables()\nDL_MODEL_FOLDER_ID \u003d variables[\"standard\"][\"dl_model_folder_id\"]\nDL_MODELS_DATA_FOLDER \u003d dataiku.Folder(DL_MODEL_FOLDER_ID)\nLABEL_MAPPING \u003d {\u0027very negative\u0027: 0, \u0027negative\u0027: 1, \u0027neutral\u0027: 2, \u0027positive\u0027: 3, \u0027very positive\u0027: 4}\nINDEX_MAPPING \u003d {v: k for k, v in LABEL_MAPPING.items()}"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Input"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tweets_eval \u003d dataiku.Dataset(\"tweets_eval\")\neval_df \u003d tweets_eval.get_dataframe()\neval_df \u003d eval_df.sample(5000)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the Logistic Regression model\ndl_model_path \u003d DL_MODELS_DATA_FOLDER.list_paths_in_partition()[-1]\nnn_name \u003d dl_model_path.split(\"/\")[-1].split(\".pkl\")[0]\n\n# load latest Deep Learning model\nwith tempfile.TemporaryDirectory() as temp_directory_name:\n\n    local_file_path \u003d temp_directory_name + \"/\" + nn_name\n\n    # Copy file from remote to local\n    with DL_MODELS_DATA_FOLDER.get_download_stream(dl_model_path) as f_remote, open(local_file_path,\u0027wb\u0027) as f_local:\n        shutil.copyfileobj(f_remote, f_local)\n\n    # Load the pipeline\n    with open(local_file_path, \u0027rb\u0027) as file:\n        nn_model \u003d pickle.load(file)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocess the data\ny \u003d eval_df[\u0027label\u0027]\nX_eval, y_eval \u003d preprocess_data_for_dl(eval_df[[\u0027tweet_length_chars\u0027, \u0027tweet_length_words\u0027, \u0027text\u0027]], y)\n\n# Predict\neval_prediction_results_df \u003d eval_df.copy()\n\n# Create class probabilities columns\nclass_probabilities \u003d nn_model.predict(X_eval)\nlatest_class_proba \u003d 0\nfor i in range(class_probabilities.shape[1]):\n    if class_probabilities[:, i] \u003e latest_class_proba:\n        eval_prediction_results_df[\u0027predictied_class_index\u0027] \u003d class_probabilities[:, i]\n    class_name \u003d INDEX_MAPPING[i]\n    eval_prediction_results_df[f\u0027{class_name}_probability\u0027] \u003d class_probabilities[:, i]\n    latest_class_proba \u003d class_probabilities[:, i]\n    \n# Create the prediction column\neval_prediction_results_df[\u0027max_probability\u0027] \u003d class_probabilities.max(axis\u003d1)\neval_prediction_results_df[\u0027prediction\u0027] \u003d eval_prediction_results_df.filter(like\u003d\u0027_probability\u0027).idxmax(axis\u003d1).str.replace(\u0027_probability\u0027, \u0027\u0027)\n\n# Move label column next to prediction\ncols \u003d eval_prediction_results_df.columns.tolist()\ncols.remove(\u0027label\u0027)\ncols.insert(cols.index(\u0027prediction\u0027), \u0027label\u0027)\neval_prediction_results_df \u003d eval_prediction_results_df[cols]\n\neval_prediction_results_df[\u0027correct_prediction\u0027] \u003d eval_prediction_results_df[\u0027label\u0027] \u003d\u003d eval_prediction_results_df[\u0027prediction\u0027]\n\neval_prediction_results_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate evaluation metrics\nprint(y_eval)\naccuracy \u003d accuracy_score(y_eval, eval_prediction_results_df[\u0027max_probability\u0027])\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "precision \u003d precision_score(y_eval, eval_prediction_results_df[\u0027max_probability\u0027], average\u003d\u0027weighted\u0027)\nrecall \u003d recall_score(y_eval, eval_prediction_results_df[\u0027max_probability\u0027], average\u003d\u0027weighted\u0027)\nf1 \u003d f1_score(y_eval, eval_prediction_results_df[\u0027max_probability\u0027], average\u003d\u0027weighted\u0027)\nroc_auc \u003d roc_auc_score(y_eval, nn_model.predict_proba(X_eval), multi_class\u003d\u0027ovr\u0027, average\u003d\u0027weighted\u0027)\n\n# Drop max_probability\neval_prediction_results_df \u003d eval_prediction_results_df.drop(\u0027max_probability\u0027)\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(f\"ROC AUC: {roc_auc}\")\n\neval_metrics_df \u003d pd.DataFrame({\n    \u0027Mean Accuracy\u0027: [accuracy],\n    \u0027Mean Precision\u0027: [precision],\n    \u0027Mean Recall\u0027: [recall],\n    \u0027Mean F1 Score\u0027: [f1],\n    \u0027Mean ROC AUC\u0027: [roc_auc],\n    \u0027Model Name\u0027: [\u0027Neural Network\u0027],\n    \u0027Date and Time\u0027: [datetime.now().strftime(\u0027%Y-%m-%d %H:%M:%S\u0027)]\n})"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Output"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe outputs\neval_prediction_results \u003d dataiku.Dataset(\"dl_eval_prediction_results\")\neval_prediction_results.write_with_schema(eval_prediction_results_df)\n\neval_metrics \u003d dataiku.Dataset(\"dl_eval_metrics\")\neval_metrics.write_with_schema(eval_metrics_df)"
      ],
      "outputs": []
    }
  ]
}