{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in CPU-XL-2-cpu-16Gb-Ram (env edf_sentiment_analysis)",
      "language": "python",
      "name": "py-dku-containerized-venv-edf_sentiment_analysis-cpu-xl-2-cpu-16gb-ram"
    },
    "associatedRecipe": "recipe_from_notebook_9_machine_learning",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "anne-soline.guilbert-ly@dataiku.com"
      },
      "lastModifiedOn": 1742812779766
    },
    "creator": "anne-soline.guilbert-ly@dataiku.com",
    "createdOn": 1742812779766,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "import dataiku\n",
        "from dataiku import pandasutils as pdu\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "prepared_tweets_encryption \u003d dataiku.Dataset(\"prepared_tweets_encryption\")\n",
        "prepared_tweets_encryption_df \u003d prepared_tweets_encryption.get_dataframe()\n",
        "\n",
        "prepared_tweets_removal \u003d dataiku.Dataset(\"prepared_tweets_removal\")\n",
        "prepared_tweets_removal_df \u003d prepared_tweets_removal.get_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def apply_and_evaluate_model_with_tfidf_stratified_kfold(df, label_col\u003d\u0027label\u0027, n_splits\u003d5, max_features\u003d5000):\n",
        "\n",
        "    # Step 2: Split dataset into features and target\n",
        "    # Handle date, user, and language as dummy variables\n",
        "    X \u003d pd.get_dummies(df[[\u0027date\u0027, \u0027user\u0027, \u0027language\u0027]], drop_first\u003dTrue)\n",
        "\n",
        "    # Handle numerical columns with standard scaling\n",
        "    numerical_cols \u003d [\u0027tweet_length_chars\u0027, \u0027tweet_length_words\u0027, \u0027repetitive_letters\u0027,\n",
        "                      \u0027mention_only\u0027, \u0027unreadable\u0027, \u0027too_many_numbers\u0027]\n",
        "    scaler \u003d StandardScaler()\n",
        "    X_numerical \u003d scaler.fit_transform(df[numerical_cols].fillna(0))\n",
        "    X_numerical \u003d pd.DataFrame(X_numerical, columns\u003dnumerical_cols, index\u003ddf.index)\n",
        "\n",
        "    # Concatenate all features\n",
        "    X \u003d pd.concat([X, X_numerical], axis\u003d1)\n",
        "    y \u003d df[label_col]\n",
        "\n",
        "    # Step 3: Apply TF-IDF transformation on the text column\n",
        "    tfidf \u003d TfidfVectorizer(\n",
        "        min_df\u003d0.01,  # Adjusted min_df to a lower value\n",
        "        max_df\u003d0.9,   # Adjusted max_df to a higher value\n",
        "        ngram_range\u003d(1, 1),\n",
        "        stop_words\u003dNone\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        X_tfidf \u003d tfidf.fit_transform(df[\u0027text\u0027].fillna(\u0027\u0027))\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during TF-IDF transformation: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Combine TF-IDF features with other features\n",
        "    X_combined \u003d np.hstack((X.values, X_tfidf.toarray()))\n",
        "\n",
        "    # Step 4: Stratified K-Fold Cross Validation\n",
        "    skf \u003d StratifiedKFold(n_splits\u003dn_splits, shuffle\u003dTrue, random_state\u003d42)\n",
        "    accuracies \u003d []\n",
        "    reports \u003d []\n",
        "    roc_aucs \u003d []\n",
        "\n",
        "    for train_index, test_index in skf.split(X_combined, y):\n",
        "        X_train, X_test \u003d X_combined[train_index], X_combined[test_index]\n",
        "        y_train, y_test \u003d y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Define the model\n",
        "        model \u003d LogisticRegression(max_iter\u003d1000)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred \u003d model.predict(X_test)\n",
        "        y_pred_proba \u003d model.predict_proba(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy \u003d accuracy_score(y_test, y_pred)\n",
        "        report \u003d classification_report(y_test, y_pred, output_dict\u003dTrue)\n",
        "\n",
        "        try:\n",
        "            roc_auc \u003d roc_auc_score(y_test, y_pred_proba, multi_class\u003d\u0027ovr\u0027)\n",
        "        except ValueError as e:\n",
        "            print(f\"Error during ROC AUC calculation: {e}\")\n",
        "            roc_auc \u003d None\n",
        "\n",
        "        accuracies.append(accuracy)\n",
        "        reports.append(report)\n",
        "        roc_aucs.append(roc_auc)\n",
        "\n",
        "    return np.mean(accuracies), reports, np.mean([auc for auc in roc_aucs if auc is not None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Apply to prepared_tweets_encryption_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Apply the function to each DataFrame\n",
        "accuracy_encrypted, report_encrypted, roc_auc_encrypted \u003d apply_and_evaluate_model_with_tfidf_stratified_kfold(prepared_tweets_encryption_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "if accuracy_encrypted is not None:\n",
        "    encrypted_metrics_df \u003d pd.DataFrame({\n",
        "        \u0027Metric\u0027: [\u0027Average Accuracy\u0027, \u0027Average ROC AUC\u0027],\n",
        "        \u0027Value\u0027: [accuracy_encrypted, roc_auc_encrypted]\n",
        "    })\n",
        "    print(encrypted_metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "encrypted_metrics_per_fold_df \u003d pd.DataFrame()\n",
        "\n",
        "for i, report in enumerate(report_encrypted):\n",
        "    if isinstance(report, dict):\n",
        "        # Remove \u0027accuracy\u0027, \u0027macro avg\u0027, and \u0027weighted avg\u0027 from the report\n",
        "        report.pop(\u0027accuracy\u0027, None)\n",
        "        report.pop(\u0027macro avg\u0027, None)\n",
        "        report.pop(\u0027weighted avg\u0027, None)\n",
        "\n",
        "        report_df \u003d pd.DataFrame.from_dict(report).transpose()\n",
        "        report_df[\u0027class\u0027] \u003d report_df.index  # Save the key of each dictionary into a new column called \"class\"\n",
        "        report_df[\u0027Fold\u0027] \u003d i + 1  # Add the fold number to the DataFrame\n",
        "        encrypted_metrics_per_fold_df \u003d pd.concat([encrypted_metrics_per_fold_df, report_df], ignore_index\u003dTrue)\n",
        "    else:\n",
        "        print(f\"Warning: Report for Fold {i+1} is not a dictionary and cannot be converted to a DataFrame.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Apply to prepared_tweets_removal_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "accuracy_removed, report_removed, roc_auc_removed \u003d apply_and_evaluate_model_with_tfidf_stratified_kfold(prepared_tweets_removal_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "if accuracy_removed is not None:\n",
        "    removed_metrics_df \u003d pd.DataFrame({\n",
        "        \u0027Metric\u0027: [\u0027Average Accuracy\u0027, \u0027Average ROC AUC\u0027],\n",
        "        \u0027Value\u0027: [accuracy_removed, roc_auc_removed]\n",
        "    })\n",
        "    print(removed_metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "removed_metrics_per_fold_df \u003d pd.DataFrame()\n",
        "\n",
        "for i, report in enumerate(report_removed):\n",
        "    if isinstance(report, dict):\n",
        "        # Remove \u0027accuracy\u0027, \u0027macro avg\u0027, and \u0027weighted avg\u0027 from the report\n",
        "        report.pop(\u0027accuracy\u0027, None)\n",
        "        report.pop(\u0027macro avg\u0027, None)\n",
        "        report.pop(\u0027weighted avg\u0027, None)\n",
        "\n",
        "        report_df \u003d pd.DataFrame.from_dict(report).transpose()\n",
        "        report_df[\u0027class\u0027] \u003d report_df.index  # Save the key of each dictionary into a new column called \"class\"\n",
        "        report_df[\u0027Fold\u0027] \u003d i + 1  # Add the fold number to the DataFrame\n",
        "        removed_metrics_per_fold_df \u003d pd.concat([removed_metrics_per_fold_df, report_df], ignore_index\u003dTrue)\n",
        "    else:\n",
        "        print(f\"Warning: Report for Fold {i+1} is not a dictionary and cannot be converted to a DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe outputs\n",
        "encrypted_metrics \u003d dataiku.Dataset(\"encrypted_metrics\")\n",
        "encrypted_metrics.write_with_schema(encrypted_metrics_df)\n",
        "\n",
        "encrypted_metrics_per_fold \u003d dataiku.Dataset(\"encrypted_metrics_per_fold\")\n",
        "encrypted_metrics_per_fold.write_with_schema(encrypted_metrics_per_fold_df)\n",
        "\n",
        "removed_metrics \u003d dataiku.Dataset(\"removed_metrics\")\n",
        "removed_metrics.write_with_schema(removed_metrics_df)\n",
        "\n",
        "removed_metrics_per_fold \u003d dataiku.Dataset(\"removed_metrics_per_fold\")\n",
        "removed_metrics_per_fold.write_with_schema(removed_metrics_per_fold_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Parameter grid for GridSearchCV\n",
        "param_grid \u003d {\n",
        "    \u0027lr__alpha\u0027: [0.01, 0.1, 1, 10],\n",
        "    \u0027lr__l1_ratio\u0027: [0, 0.4, 0.8, 1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# GridSearchCV\n",
        "grid_search \u003d GridSearchCV(pipeline,\n",
        "                           param_grid,\n",
        "                           cv\u003d5,\n",
        "                           scoring\u003d\u0027neg_mean_squared_error\u0027,\n",
        "                           verbose\u003d1)\n",
        "grid_search.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Format results\n",
        "cv_results \u003d pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# select columns\n",
        "selected_cols \u003d [\"mean_fit_time\"] + [c for c in cv_results if \"param_\" in c or \"_test_score\" in c]\n",
        "selected_cols.remove(\"std_test_score\")\n",
        "cv_results \u003d cv_results[selected_cols]\n",
        "\n",
        "# rank experiments\n",
        "cv_results \u003d cv_results.sort_values(\"rank_test_score\")\n",
        "\n",
        "# pretty rf params\n",
        "cv_results \u003d cv_results.rename({\"param_lr__alpha\": \"alpha\",\n",
        "                                \"param_lr__l1_ratio\": \"l1_ratio\"},\n",
        "                                axis\u003d1)\n",
        "cv_results[\"date\"] \u003d datetime.now().date()\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "artefact_name \u003d f\"lr_{datetime.now().strftime(\u0027%Y-%m-%d_%H-%M-%S\u0027)}\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Pipeline\n",
        "pipeline_local_path \u003d f\"{artefact_name}.pkl\"\n",
        "pipeline_remote_path \u003d f\"{artefact_name}.pkl\"\n",
        "remote_output_folder \u003d dataiku.Folder(\"2T1uAdOy\")\n",
        "\n",
        "with tempfile.TemporaryDirectory() as local_tmp_dir:\n",
        "\n",
        "    local_file_path \u003d os.path.join(local_tmp_dir, pipeline_local_path)\n",
        "\n",
        "    with open(local_file_path, \u0027wb\u0027) as file:\n",
        "        pickle.dump(grid_search.best_estimator_, file)\n",
        "\n",
        "    remote_output_folder.upload_file(pipeline_remote_path, local_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training stats\n",
        "cv_results[\"model\"] \u003d artefact_name  # save model name\n",
        "dataiku\\\n",
        "    .Dataset(\"lr_training_stats\")\\\n",
        "    .write_with_schema(cv_results[:1].drop(\"rank_test_score\", axis\u003d1))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Artefacts\n",
        "fi_local_path \u003d f\"{artefact_name}_feature_importance.png\"\n",
        "fi_remote_path \u003d f\"{artefact_name}_feature_importance.png\"\n",
        "output_folder \u003d dataiku.Folder(\"JPo1Lx1F\")\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmp_dir_name:\n",
        "    local_file_path \u003d os.path.join(tmp_dir_name, fi_local_path)\n",
        "    fig \u003d ax.get_figure()\n",
        "    fig.savefig(fi_local_path)\n",
        "    output_folder.upload_file(fi_remote_path, fi_local_path)\n",
        "    plt.close(fig)"
      ]
    }
  ]
}