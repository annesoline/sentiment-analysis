{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-edf_sentiment_analysis",
      "display_name": "Python (env edf_sentiment_analysis)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "anne-soline.guilbert-ly@dataiku.com",
    "modifiedBy": "anne-soline.guilbert-ly@dataiku.com",
    "tags": [],
    "customFields": {},
    "createdOn": 1741861109008
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n%load_ext ai_code_assistant"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install kaggle\n!export KAGGLE_USERNAME\u003d\"annesoline@proton.me\"\n!export KAGGLE_KEY\u003d\"e:AES:X2:tA0A0uWnU6nmbTIHPYxt1KksBcxesTbzZjrhR7Lhs1RAmykk6gUGD5D9Qd9g+xnDWgAyKsGU5+JH4dnA4AfkTzaIQfSpBsjpmmi2JwfQdY4\u003d\"\n!kaggle datasets download kazanova/sentiment140\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auth_info \u003d client.get_auth_info(with_secrets\u003dTrue)\nclient \u003d da\nsecret_value \u003d None\nfor secret in auth_info[\"secrets\"]:\n    if secret[\"key\"] \u003d\u003d \"KAGGLE_KEY\":\n        os.environ[\"KAGGLE_KEY\"] \u003d secret[\"value\"]\n        break\n    if secret[\"key\"] \u003d\u003d \"KAGGLE_USERNAME\":\n        os.environ[\"KAGGLE_USERNAME\"] \u003d secret[\"value\"]\n        break\nif not secret_value:\n    raise Exception(\"secret not found\")\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport os\nimport kaggle\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\nmydataset \u003d dataiku.Dataset(\"mydataset\")\nmydataset_df \u003d mydataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlcroissant as mlc"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Fetch the Croissant JSON-LD\ncroissant_dataset \u003d mlc.Dataset(\u0027https://www.kaggle.com/datasets/kazanova/sentiment140/croissant/download\u0027)\n\n# Check what record sets are in the dataset\nrecord_sets \u003d croissant_dataset.metadata.record_sets\nprint(record_sets)\n\n# Fetch the records and put them in a DataFrame\nrecord_set_df \u003d pd.DataFrame(croissant_dataset.records(record_set\u003drecord_sets[0].uuid))\nrecord_set_df.head()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import kagglehub\n\n# Download latest version\npath \u003d kagglehub.dataset_download(\"kazanova/sentiment140\")\n\nprint(\"Path to dataset files:\", path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}