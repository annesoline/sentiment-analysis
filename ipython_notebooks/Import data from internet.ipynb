{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-edf_sentiment_analysis",
      "display_name": "Python (env edf_sentiment_analysis)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "anne-soline.guilbert-ly@dataiku.com",
    "customFields": {},
    "modifiedBy": "anne-soline.guilbert-ly@dataiku.com",
    "createdOn": 1741861109008,
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%load_ext ai_code_assistant"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nimport os"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project \u003d dataiku.api_client().get_default_project()\nclient \u003d dataiku.api_client()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieve Kaggle username and api key\nauth_info \u003d client.get_auth_info(with_secrets\u003dTrue)\nsecret_value \u003d None\nfor secret in auth_info[\"secrets\"]:\n    if secret[\"key\"] \u003d\u003d \"KAGGLE_API_KEY\":\n        os.environ[\"KAGGLE_API_KEY\"] \u003d secret[\"value\"]\n        \n    elif secret[\"key\"] \u003d\u003d \"KAGGLE_USERNAME\":\n        os.environ[\"KAGGLE_USERNAME\"] \u003d secret[\"value\"]\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieve the folder id where the dataset will be stored\nfolder_id \u003d next((folder[\"id\"] for folder in project.list_managed_folders() if folder[\"name\"]\u003d\u003d\"data\"), None)\nif folder_id is None:\n    print(\"Folder \u0027data\u0027 not found!\")\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set the folder path where the dataset will be stored\nfolder \u003d dataiku.Folder(folder_id)\nfolder_path \u003d folder.get_path()\nprint(folder_path)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import kaggle"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download the Kaggle dataset from internet\ndataset_slug \u003d \"kazanova/sentiment140\"\nkaggle.api.dataset_download_files(dataset_slug, path\u003dfolder_path, unzip\u003dTrue)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the dataframe from the csv file\ndataset_info \u003d kaggle.api.dataset_metadata(dataset_slug)\ndataset_title \u003d dataset_info[\"title\"]\ndataset_name \u003d dataset_title + \".csv\"\nannotated_tweets_df \u003d pd.read_csv(os.path.join(folder_path, dataset_name))\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\nannotated_tweets \u003d dataiku.Dataset(\"annotated_tweets\")\nannotated_tweets.write_with_schema(annotated_tweets_df)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import kagglehub\n\n# Download latest version\npath \u003d kagglehub.dataset_download(\"kazanova/sentiment140\")\n\nprint(\"Path to dataset files:\", path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlcroissant as mlc\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Fetch the Croissant JSON-LD\ncroissant_dataset \u003d mlc.Dataset(\u0027https://www.kaggle.com/datasets/kazanova/sentiment140/croissant/download\u0027)\n\n# Check what record sets are in the dataset\nrecord_sets \u003d croissant_dataset.metadata.record_sets\nprint(record_sets)\n\n# Fetch the records and put them in a DataFrame\nrecord_set_df \u003d pd.DataFrame(croissant_dataset.records(record_set\u003drecord_sets[0].uuid))\nrecord_set_df.head()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport matplotlib.pyplot as plt"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\ntweets \u003d dataiku.Dataset(\"tweets\")\ndf \u003d tweets.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\u0027flag\u0027].unique()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\u0027user\u0027].nunique()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\u0027tweet_length_chars\u0027] \u003d df[\u0027text\u0027].str.len()\ndf[\u0027tweet_length_words\u0027] \u003d df[\u0027text\u0027].str.split().apply(len)\ndf.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize\u003d(10,5))\nplt.hist(df[\u0027tweet_length_chars\u0027], bins\u003d20, color\u003d\u0027blue\u0027, alpha\u003d0.7)\nplt.xlabel(\"Tweet lenght (in characters)\")\nplt.ylabel(\"Number of tweets\")\nplt.title(\"Distribution of tweets length\")\nplt.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}