{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "hide_input": false,
    "creator": "anne-soline.guilbert-ly@dataiku.com",
    "dkuGit": {
      "lastInteraction": 1742206719604,
      "gitReference": {
        "remote": "git@github.com:annesoline/sentiment-analysis.git",
        "checkout": "refs/heads/main",
        "remotePath": "quality_analysis_textual_data.ipynb",
        "lastHash": "8b4cb55b650ef4fef189f6b8f66f795212df0834",
        "lastTimestamp": 1742206718000,
        "isDirty": false
      }
    },
    "createdOn": 1742205346782,
    "tags": [],
    "modifiedBy": "anne-soline.guilbert-ly@dataiku.com"
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\nimport pandas as pd\nimport dataiku\npd.set_option(\u0027display.max_colwidth\u0027, None)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Load tweets dataset"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imported_tweets \u003d dataiku.Dataset(\"imported_tweets\")\ndf \u003d imported_tweets.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.head()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Textual data quality analysis\n## 2.1. Basic information"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Values taken by the column flag: {df[\u0027flag\u0027].unique()[0]}\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"There are {df[\u0027user\u0027].nunique()} different users.\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for empty tweets\nempty_tweets \u003d len(df[df[\u0027text\u0027].str.len() \u003d\u003d 0])\nprint(f\"\\nNumber of empty tweets: {empty_tweets}\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2. Tweet length"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a new dataframe with the original columns plus the new length columns\ndf \u003d df.copy()\ndf[\u0027tweet_length_chars\u0027] \u003d df[\u0027text\u0027].str.len()\ndf[\u0027tweet_length_words\u0027] \u003d df[\u0027text\u0027].str.split().apply(len)\ndf.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tweet column analysis\nprint(\"\\nTweet length statistics:\")\nprint(df[\u0027tweet_length_chars\u0027].describe())\n\n# Plot distribution of tweet lengths\nplt.figure(figsize\u003d(12,6))\nplt.hist(df[\u0027tweet_length_chars\u0027], bins\u003d50, edgecolor\u003d\u0027black\u0027)\nplt.title(\u0027Distribution of Tweet Lengths\u0027)\nplt.xlabel(\u0027Number of Characters\u0027)\nplt.ylabel(\u0027Frequency\u0027)\nplt.show()\n\n# Most common tweet lengths in words\nprint(\"\\nMost common tweet lengths (in words):\")\nprint(df[\u0027tweet_length_words\u0027].value_counts().head())"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3. Tweet specificities (characters, URL, and mentions)"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Unique characters analysis\nall_chars \u003d \u0027\u0027.join(df[\u0027text\u0027].values)\nunique_chars \u003d set(all_chars)\nprint(f\"\\nNumber of unique characters used: {len(unique_chars)}\")\nprint(f\"Unique characters used: {\u0027\u0027.join(sorted(unique_chars))}\")\n\n# Create dataframe with tweets containing repetitive characters (like \u0027aaaaaa\u0027 or \u0027!!!!!!!\u0027)\ndf_repetitive \u003d df[df[\u0027text\u0027].str.match(r\u0027.*(.)\\1{4,}.*\u0027)].copy()\nrepetitive_chars \u003d len(df_repetitive)\nprint(f\"\\nTweets with repetitive characters: {repetitive_chars} ({(repetitive_chars/len(df)*100):.2f}%)\")\nprint(\"\\nExamples of tweets with repetitive characters:\")\nprint(df_repetitive[\u0027text\u0027].head(10))\n\n\n# URL and mention analysis\ntweets_with_urls \u003d len(df[df[\u0027text\u0027].str.contains(\u0027http|www\u0027, regex\u003dTrue)])\ntweets_with_mentions \u003d len(df[df[\u0027text\u0027].str.contains(\u0027@\u0027)])\n\n# Print examples of tweets with URLs\nprint(\"\\nExample tweets containing URLs:\")\ndf_with_urls \u003d df[df[\u0027text\u0027].str.contains(\u0027http|www\u0027, regex\u003dTrue)].copy()\nprint(df_with_urls[\u0027text\u0027].head())\n\n# Print examples of tweets with mentions\nprint(\"\\nExample tweets containing @mentions:\")\nprint(df[df[\u0027text\u0027].str.contains(\u0027@\u0027)][\u0027text\u0027].head())\n\nprint(f\"\\nTweets containing URLs: {tweets_with_urls} ({tweets_with_urls/len(df)*100:.2f}%)\")\nprint(f\"Tweets containing @mentions: {tweets_with_mentions} ({tweets_with_mentions/len(df)*100:.2f}%)\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comments\nTweets with repetitive characters often contain repeated dots or letters. For the latter, we can easily eliminate the repetition in the letters, helping the model better understand the words.\n\nIt will be useful to remove all the URL from the text to ease the detection of sentiment in the text.\n\nTweets containing only a mention in the text are tagged, allowing them to be removed from the dataset later, as they provide no relevant information for sentiment analysis."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create new dataframe with mention_only column\ndf \u003d df.copy()\ndf[\u0027mention_only\u0027] \u003d df[\u0027text\u0027].str.match(r\u0027^\\s*@\\w+\\s*$\u0027).astype(int)\n\n# Print summary\nprint(f\"\\nTweets that are only mentions: {df[\u0027mention_only\u0027].sum()} ({df[\u0027mention_only\u0027].sum()/len(df)*100:.2f}%)\")\nprint(\"\\nExample tweets that are only mentions:\")\nprint(df[df[\u0027mention_only\u0027] \u003d\u003d 1][\u0027text\u0027].head())\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4. Tweets with special characters and unreadable tweets"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import string\n\nspecial_chars \u003d [c for c in unique_chars \n                if c not in string.ascii_letters \n                and c not in string.digits\n                and c not in string.punctuation\n                and not c.isalpha()\n                and c not in [\u0027¸\u0027, \u0027·\u0027, \u0027 \u0027, \u0027´\u0027, \u0027»\u0027, \u0027«\u0027]]  # Excludes accented letters, euro symbol, and specific characters\nprint(\u0027Special characters:\u0027, (sorted(special_chars)))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create new dataframe with only unreadable rows\n# Create a new column in df with a tag 1/0 if the text is unreadable\ndf[\u0027unreadable\u0027] \u003d df[\u0027text\u0027].apply(lambda x: int(sum(1 for c in x if c in special_chars) \u003e 5))\n\n# Create a new dataframe with only unreadable rows\ndf_unreadable \u003d df[df[\u0027unreadable\u0027] \u003d\u003d 1].copy()\n\n# Print summary statistics\nprint(\"\\nTweets with more than 5 special characters:\")\nprint(\"-\" * 50)\nprint(f\"\\nNumber of unreadable tweets: {len(df_unreadable)}\")\nprint(\"\\nExample unreadable tweets:\")\nprint(df_unreadable[[\u0027text\u0027]].head(10))\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show tweets containing special characters\nprint(\"\\nTweets containing special characters:\")\nprint(\"-\" * 50)\nfor char in special_chars:\n    tweets_with_char \u003d df[df[\u0027text\u0027].str.contains(char, regex\u003dFalse)]\n    if len(tweets_with_char) \u003e 0:\n        print(f\"\\nTweets containing \u0027{char}\u0027:\")\n        print(tweets_with_char[[\u0027text\u0027]].head())\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for tweets with high percentage of numbers\ndf_high_percentage_numbers \u003d df.copy()\nnumber_ratio \u003d df_high_percentage_numbers[\u0027text\u0027].str.count(r\u0027[0-9]\u0027) / df_high_percentage_numbers[\u0027tweet_length_chars\u0027]\ndf_high_percentage_numbers[\u0027too_many_numbers\u0027] \u003d (number_ratio \u003e 0.3).astype(int)\ndf[\u0027too_many_numbers\u0027] \u003d df_high_percentage_numbers[\u0027too_many_numbers\u0027]\nhigh_numbers \u003d df_high_percentage_numbers[\u0027too_many_numbers\u0027].sum()\nprint(f\"\\nTweets with high number ratio (\u003e30%): {high_numbers} ({(high_numbers/len(df_high_percentage_numbers)*100):.2f}%)\")\nprint(\"\\nExamples of tweets with many numbers:\")\nprint(df_high_percentage_numbers[df_high_percentage_numbers[\u0027too_many_numbers\u0027] \u003d\u003d 1][\u0027text\u0027].head(10))\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comments\nIn this section, we reviewed tweets containing excessive special characters that render them unreadable, and created a column to tag these tweets so they can be removed from the dataset later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5. Short tweets, repetitive characters, all caps tweets"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for very short tweets that might be low quality\n# Create a new DataFrame with only very short tweets\ndf_very_short_tweets \u003d df[df[\u0027tweet_length_chars\u0027] \u003c 10]\n\n# Count and display the number of very short tweets\nvery_short_tweets_count \u003d df_very_short_tweets.shape[0]\nprint(f\"\\nVery short tweets (\u003c10 chars): {very_short_tweets_count} ({(very_short_tweets_count/len(df)*100):.2f}%)\")\n\n# Display examples of very short tweets\nprint(\"\\nExamples of very short tweets:\")\nprint(df_very_short_tweets[\u0027text\u0027].head(10))\n\n# Check for all caps tweets (possible spam/low quality)\nall_caps_tweets \u003d df[df[\u0027text\u0027].str.match(r\u0027^[A-Z0-9\\s\\W]+$\u0027)].shape[0]\nprint(f\"\\nAll caps tweets: {all_caps_tweets} ({(all_caps_tweets/len(df)*100):.2f}%)\")\nprint(\"\\nExamples of all caps tweets:\")\nprint(df[df[\u0027text\u0027].str.match(r\u0027^[A-Z0-9\\s\\W]+$\u0027)][\u0027text\u0027].head(10))\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comments\nAs shown in the example above, very short tweets can still be used for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.6. Average punctuation marks per tweet, word/character ratio"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate average punctuation per tweet\npunct_counts \u003d df[\u0027text\u0027].str.count(f\u0027[{string.punctuation}]\u0027)\navg_punct \u003d punct_counts.mean()\nprint(f\"\\nAverage punctuation marks per tweet: {avg_punct:.2f}\")\n\n# Check for tweets with excessive punctuation\nexcessive_punct \u003d df[punct_counts \u003e punct_counts.mean() + 2*punct_counts.std()].shape[0]\nprint(f\"Tweets with excessive punctuation: {excessive_punct} ({(excessive_punct/len(df)*100):.2f}%)\")\n\n# Analyze word/character ratio (very low ratio might indicate spam or low quality)\nchar_word_ratio \u003d df[\u0027tweet_length_chars\u0027] / df[\u0027tweet_length_words\u0027]\nsuspicious_ratio \u003d df[char_word_ratio \u003e char_word_ratio.mean() + 2*char_word_ratio.std()].shape[0]\nprint(f\"\\nTweets with suspicious character-to-word ratio: {suspicious_ratio} ({(suspicious_ratio/len(df)*100):.2f}%)\")\nprint(\"\\nExamples of tweets with suspicious character-to-word ratio:\")\nprint(df[char_word_ratio \u003e char_word_ratio.mean() + 2*char_word_ratio.std()][\u0027text\u0027].head(10))\n\n# Distribution of character-to-word ratios\nplt.figure(figsize\u003d(12, 6))\nplt.hist(char_word_ratio, bins\u003d50, edgecolor\u003d\u0027black\u0027)\nplt.title(\u0027Distribution of Character-to-Word Ratios\u0027)\nplt.xlabel(\u0027Characters per Word\u0027)\nplt.ylabel(\u0027Frequency\u0027)\nplt.show()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comments\nTweets with excessive punctuations are often containing dots or a URL. Therefore, it is not necessary to remove them from the dataset. "
      ]
    }
  ]
}